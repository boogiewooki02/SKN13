{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef06541a-3111-46cb-a3be-4b50d8267e1a",
   "metadata": {},
   "source": [
    "# Transformers 를 이용해 Backbone 사용\n",
    "\n",
    "## Transformers 설치\n",
    "- `pip install transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4825a-fe9f-4d1e-b9e0-7bb78745b840",
   "metadata": {},
   "source": [
    "### Tokenizer, Model Loading\n",
    "- Huggingface 모델 허브에서 제공하는 처리 모델을 다운받아 로딩한다.\n",
    "- 다운로드된 모델은 `사용자 home 디렉토리\\.cache\\huggingface` 에 저장된다.\n",
    "- 미리 학습된 언어 모델을 다운받아 사용할 때는 그 언어모델이 사용한 tokenizer를 같이 받아서 사용한다.\n",
    "\n",
    "### [Auto Classes](https://huggingface.co/docs/transformers/model_doc/auto)\n",
    "- Huggingface 에서 제공하는 다양한 모델들은 손쉽게 불러오고 사용할 수 있도록 설계된 유틸리티 클래스들을 말한다.\n",
    "- 미리 학습된 특정 모델의 이름(모델 허브상에서 제공되는 이름)이나 저장된 local 경로를 제공하면 해당 모델에 맞는 적절한 클래스와 구성 요소를 자동으로 로드한다.\n",
    "- 사용자는 모델을 사용하기 위한 정확한 클래스를 몰라도 쉽게 다양한 종류의 모델을 사용할 수있다.\n",
    "\n",
    "#### 주요 Auto Class\n",
    "- 기본 모델 Loading\n",
    "    1. **AutoModel**\n",
    "       - 주어진 모델 이름에 맞는 사전 학습된 모델을 자동으로 로드한다.\n",
    "       - 예: `AutoModel.from_pretrained(\"bert-base-uncased\")`: BERT 모델을 로드한다.\n",
    "    2. **AutoTokenizer**\n",
    "       - 해당 모델에 적합한 토크나이저를 자동으로 로드한다.\n",
    "       - 예: `AutoTokenizer.from_pretrained(\"bert-base-uncased\")`: BERT 모델에 맞는 토크나이저를 로드한다.\n",
    "    3. **AutoConfig**\n",
    "       - 모델의 설정(config)을 자동으로 로드한다. 모델 설정에는 모델의 하이퍼파라미터와 모델 구조 정보가 포함된다. 이 설정을 이용해 모델을 생성할 수있다.\n",
    "       - 예: `AutoConfig.from_pretrained(\"bert-base-uncased\")`\n",
    "- Task 처리 모델 Loading\n",
    "    - Pretrained backbone 모델에 각 task 에 맞는 estimator layer를 추가한 모델을 생성해 제공한다.\n",
    "    - 주요 모델들\n",
    "        1. **AutoModelForSequenceClassification**\n",
    "           - 시퀀스(Text) 분류 작업을 위한 모델을 자동으로 로드한다.\n",
    "           - 예: `AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")`\n",
    "        2. **AutoModelForQuestionAnswering**\n",
    "           - 질문-응답 작업을 위한 모델을 자동으로 로드한다.\n",
    "           - 예: `AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")`\n",
    "        3. **AutoModelForTokenClassification**\n",
    "           - 토큰 분류 작업(예: 개체명 인식)을 위한 모델을 자동으로 로드한다.\n",
    "           - 예: `AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b9ab90-27b3-4e3a-b907-8c6345552ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef773cb-9947-4b0b-9deb-16bb7ea1b61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ab774ee0d0406d8e3982d870cb23b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\dl\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Playdata\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421d578369ff4956b77443371c0e3634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d984e767e7c14e789e073fb91253a67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300bd05a50024c51a6a1847bedb2d828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd856a504ce44f9ba1e192e118c0fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b52e02f42594f1396ba73e7bd995eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n",
      "<class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\n"
     ]
    }
   ],
   "source": [
    "# model_id = \"bert-base-uncased\"\n",
    "model_id = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(type(tokenizer))\n",
    "\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "print(type(model))\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "print(type(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c903e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  40,  716,  257, 2933,   13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_txt = \"I am a boy.\"\n",
    "token = tokenizer(\n",
    "    raw_txt,\n",
    "    return_tensors=\"pt\" # 토큰화 결과를 torch.Tensor으로 반환 (default는 list임)\n",
    ")\n",
    "token\n",
    "# input_ids: 토큰 id\n",
    "# attention_mask: input_ids의 각 토큰들이 실제 토큰인지 [PAD] 토큰인지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5415fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7081087c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D(nf=2304, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=768)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D(nf=3072, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=3072)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector = model(**token)\n",
    "# context_vector = model(input_ids=token['input_ids'], attention_mask=token['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d7741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.last_hidden_state.shape\n",
    "# torch.Size([1, 5, 768])\n",
    "# 1: 문장(문서) 개수, 5: 토큰 수, 768: embedding vector 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2315b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 확인\n",
    "t = tokenizer.encode(\"I am a boy.\") # token id만 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ab0931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a boy.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2fff303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 토큰 확인\n",
    "tokenizer.convert_tokens_to_ids(\"am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5817e575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(321)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a02d44-7271-4db4-b8c0-7c14037dce3a",
   "metadata": {},
   "source": [
    "## kcbert\n",
    "- BERT 모델을 한글 텍스트로 학습 시킨 Pretrained model.\n",
    "    - BERT는 Transformer의 Encoder 부분을 이용해 구현된 언어모델\n",
    "    - https://arxiv.org/abs/1810.04805 \n",
    "- https://huggingface.co/beomi/kcbert-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af872e-410e-4a3c-8ec3-2b1e1a680ad6",
   "metadata": {},
   "source": [
    "### 토크나이저 모델 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2518bce-6fd0-4512-9d59-0def0653095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_id = \"beomi/kcbert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b49f357b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(300, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28171f1e-7588-4583-b027-224ab6e09c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf5087a1-04bb-4b36-912f-c1c5bdd77101",
   "metadata": {},
   "source": [
    "### 입력값 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d78342de-1a9c-4b70-a997-c7bca15432ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"안녕\",\n",
    "    \"Hugging Face는 인공지능(AI)과 자연어 처리(NLP) 분야에서 혁신적인 도구와 모델을 제공하는 AI 스타트업이다.\",\n",
    "    \"2016년에 설립된 이 회사는 주로 오픈소스 라이브러리와 사전 학습된 NLP 모델을 제공을 제공한다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918a72c-9240-4173-bd94-a734ee5e946e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 19017, 3], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = tokenizer(sentences[0])\n",
    "token\n",
    "# input_ids: 토큰 id들\n",
    "# token_type_ids: 입력이 두 종류의 문장(문서)으로 구성된 경우, 각 토큰이 어떤 종류인지 구분\n",
    "# attention_mask: input_ids의 개별 토큰들이 실제 값인지 아니면 [PAD]인지 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ac67024-c95b-48cf-8329-ae3b59f5a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = tokenizer(\n",
    "    sentences,\n",
    "    max_length=10, # padding(추가하기)과 truncation(자르기)의 기준 길이 지정\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fee1ddf2-e148-43d6-ac7d-30dfa414aa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 19017,     3,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    2,    41,  4223,  4403,  4403, 18940,    39,  4243,  4773,     3],\n",
       "        [    2, 26182,  4113, 20684,  4130,  2451, 22088, 20002, 15999,     3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52498095-7fb8-4da1-9103-d22b10e9ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1dbe0052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list['token_type_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19acd0fe-5952-4ee6-97ee-e4fcf41ec093",
   "metadata": {},
   "source": [
    "### BERT 모델을 이용해 context vector 추출\n",
    "#### Model 추론결과\n",
    "- **last_hidden_state**\n",
    "    - 모든 token들에 대한 feature\n",
    "    - 출력이 **many**인 작업에 사용한다.\n",
    "- **pooler_output**\n",
    "    - 입력 문장, 텍스트에 대한 context vector 이다.\n",
    "    - 이 값은 **문장을 입력받아 처리하는 task**(ex: 문서분류-감정분석,문장카테고리분류, 문장유사도 분석)의 입력으로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42e0659e-22b0-47b0-96e6-037d9befad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "310bcd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd64977f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-4.3785e-01, -1.1922e+00,  1.9459e+00,  ...,  4.2119e-01,\n",
       "           9.8295e-01,  1.0119e+00],\n",
       "         [-3.0053e-01, -1.1015e+00,  9.0584e-01,  ...,  6.9805e-01,\n",
       "           6.8852e-01,  9.2259e-01],\n",
       "         [-8.9004e-01, -6.8068e-01,  8.9948e-01,  ...,  6.0443e-01,\n",
       "           7.3096e-01, -3.4560e-01],\n",
       "         ...,\n",
       "         [-1.0742e+00, -1.8177e-01,  2.3927e+00,  ...,  1.9575e+00,\n",
       "           3.9581e-01,  9.9546e-01],\n",
       "         [-9.4360e-01, -2.6620e-01,  2.2696e+00,  ...,  1.5724e+00,\n",
       "           3.0022e-01,  3.3455e-01],\n",
       "         [-8.0589e-01, -5.7948e-01,  2.3011e+00,  ...,  1.8778e+00,\n",
       "          -2.1813e-01, -4.0344e-01]],\n",
       "\n",
       "        [[ 2.0945e-01, -7.9768e-01,  9.5041e-01,  ..., -3.0953e-01,\n",
       "           1.0519e+00,  2.2225e-01],\n",
       "         [-1.0890e+00,  3.9076e-02,  1.5402e+00,  ..., -1.2150e+00,\n",
       "          -4.4001e-01, -9.4009e-02],\n",
       "         [-2.3940e-01,  9.3101e-01,  8.0560e-01,  ..., -3.4402e-01,\n",
       "           1.6356e+00, -4.1396e-01],\n",
       "         ...,\n",
       "         [ 6.9418e-01,  1.0629e+00,  2.6320e+00,  ..., -2.4039e+00,\n",
       "           1.9444e-01,  2.2092e-04],\n",
       "         [-1.1400e+00, -1.2212e+00,  1.8446e+00,  ...,  1.2197e+00,\n",
       "          -2.6859e-01, -1.3965e-01],\n",
       "         [-1.4150e+00,  2.1216e-01,  1.7449e+00,  ..., -5.0862e-01,\n",
       "          -6.1128e-01,  1.9586e-01]],\n",
       "\n",
       "        [[ 3.8136e-01, -1.5147e+00, -7.2155e-01,  ..., -9.2280e-01,\n",
       "           8.8071e-01,  1.0243e+00],\n",
       "         [ 3.6184e-01,  5.5185e-02, -3.3489e-01,  ..., -1.1308e+00,\n",
       "          -2.6383e-01, -7.1887e-01],\n",
       "         [ 3.1484e-01, -1.3140e+00,  1.1756e+00,  ..., -2.9321e-02,\n",
       "           5.0868e-01,  1.7157e+00],\n",
       "         ...,\n",
       "         [ 1.1209e+00, -6.6028e-01,  8.7914e-02,  ..., -2.1309e+00,\n",
       "           2.6964e-01,  1.2411e+00],\n",
       "         [ 5.4776e-01, -1.0262e+00, -5.9584e-01,  ..., -4.7732e-01,\n",
       "           4.0248e-01, -1.7296e-01],\n",
       "         [-1.0015e-01,  4.2142e-02,  8.4825e-01,  ..., -1.1329e-01,\n",
       "          -1.2639e-01,  4.2021e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.2350,  0.1542, -0.0300,  ...,  0.5988,  0.2245, -0.9861],\n",
       "        [-0.9838, -0.1031, -0.0013,  ...,  0.1512,  0.3930, -0.9811],\n",
       "        [-0.8936,  0.1258,  0.1495,  ...,  0.4374,  0.0865, -0.9971]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71e3e35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['pooler_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82b445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
