{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907e923a-af5e-48c3-9664-58bd640efb20",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "![rag_embedding](figures/rag_embedding.png)\n",
    "\n",
    "- 분할된 텍스트를 벡터 표현(임베딩 벡터)으로 변환한다.\n",
    "- LangChain은 OpenAI, HuggingFace 등 다양한 임베딩 모델을 지원하며, 동일한 인터페이스로 사용할 수 있다.\n",
    "- [임베딩모델의 메서드](https://api.python.langchain.com/en/latest/embeddings/langchain_core.embeddings.embeddings.Embeddings.html#langchain_core.embeddings.embeddings.Embeddings)\n",
    "\n",
    "    - **`embed_documents(texts: List[str])`**\n",
    "        - 여러 문서를 받아 벡터화(임베딩)한다.\n",
    "        - Context를 벡터화 할 때 사용한다.\n",
    "    - **`embed_query(text: str)`**\n",
    "        - 하나의 문자열(문서)을 받아 벡터화한다.\n",
    "        - Query를 벡터화 할 때 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff941301-56f5-4219-89e8-6b54d5afd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "        \"나는 고양이와 개 중 반려동물로 개를 키우고 싶습니다.\",\n",
    "        \"이 강아지 품종은 진도개 입니다. 국제 표준으로 중대형견으로 분류되며 다리가 길어 체고가 높은 편에 속합니다.\",\n",
    "        \"日本の市内バスの運賃は主に距離によって決まり、地域やバス会社によって異なる場合があります\",                  # 일본의 시내버스 요금은 주로 거리에 따라 결정되며, 지역 및 버스 회사에 따라 다를 수 있습니다.\n",
    "        \"Bus fares in the United States vary from city to city, but are generally around $2.90 for a regular bus.\",  # 미국의 버스 요금은 도시마다 다르지만, 일반적으로 정기 버스의 경우 2.90달러 정도입니다.\n",
    "        \"광역버스 요금은 일반 3000원, 청소는 1800원, 어린이 1500원 입니다.\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a8b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# 1) OpenAI 사용\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "e_model_id = \"text-embedding-3-small\"\n",
    "embedding_model = OpenAIEmbeddings(model=e_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "839f86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# 2) Ollama 사용\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "e_model_id = \"bge-m3\"\n",
    "embedding_model = OllamaEmbeddings(model=e_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11534c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5276d078a754953bf3c77c4afb5ba6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\anaconda3\\envs\\lang_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Playdata\\.cache\\huggingface\\hub\\models--intfloat--multilingual-e5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc958ab45964ef9a5a2d391d6d3a223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649dd3aa3b9444f9ae4a1c81eec59bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d50331ad194a8f9a74e73beeef0325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2d50b7be81479f85c43bdae2ee6fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9600ef434a7c499f84b955d225c74bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c52cf2fbc20414aa0aa5fad1b76cb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcec9f3164994f05aaed818d06331425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a2a72da5b3405aa6b1a6d49a377b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde8465722284f1b91025fa25a86174b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################\n",
    "# 3) Huggingface 사용\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "e_model_id = \"intfloat/multilingual-e5-large\"\n",
    "embedding_model = HuggingFaceEmbeddings(model=e_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11d02ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서들을 embedding\n",
    "embedded_docs = embedding_model.embed_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c057d1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedded_docs), type(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "465811fa-32dd-44f3-96f9-c6193cb414ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1024)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.shape(embedded_docs)\n",
    "# (5: 문서 개수, 1536: 개별 문서의 embedding 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a1d35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1: np.ndarray|list, v2: np.ndarray|list)->float:\n",
    "    # v1, v2의 코사인 유사도를 반환하는 함수\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    return (v1 @ v2) / (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "## 코사인 유사도 (-1 ~ 1 사이 값)\n",
    "# 1: 매우 유사함\n",
    "# 0: 관계 없는 것\n",
    "# -1: 정확하게 반대 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "937e63ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"당신이 좋아하는 동물은 무엇인가요?\"\n",
    "embedded_query = embedding_model.embed_query(text=query)\n",
    "\n",
    "np.shape(embedded_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.36055681135000084\n",
      "2. 0.26502894656727843\n",
      "3. 0.04863998198846294\n",
      "4. -0.009661540805491114\n",
      "5. 0.06463066481689705\n"
     ]
    }
   ],
   "source": [
    "# embedded_query와 embedded_docs 간의 코사인 유사도 계산 (1)\n",
    "for i, ev in enumerate(embedded_docs):\n",
    "    print(f\"{i+1}. {cosine_similarity(ev, embedded_query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.6662511687008726\n",
      "2. 0.4408926487024179\n",
      "3. 0.20180528508045684\n",
      "4. 0.224805009320678\n",
      "5. 0.26837513265566254\n"
     ]
    }
   ],
   "source": [
    "# embedded_query와 embedded_docs 간의 코사인 유사도 계산 (2)\n",
    "for i, ev in enumerate(embedded_docs):\n",
    "    print(f\"{i+1}. {cosine_similarity(ev, embedded_query)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35aa4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 0.8452872050559566\n",
      "2. 0.7992489104879116\n",
      "3. 0.7132940936416443\n",
      "4. 0.6920042253310208\n",
      "5. 0.7591988811567014\n"
     ]
    }
   ],
   "source": [
    "# embedded_query와 embedded_docs 간의 코사인 유사도 계산 (3)\n",
    "for i, ev in enumerate(embedded_docs):\n",
    "    print(f\"{i+1}. {cosine_similarity(ev, embedded_query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d02707-99d9-4d48-826f-ae446a405fc6",
   "metadata": {},
   "source": [
    "# 벡터 데이터베이스(Vector Database)\n",
    "- Embedding 된 문서를 Vector Database(Vector Store)에 저장한다.\n",
    "- 이후 질문(Query)와 관련된 내용을 유사도를 이용해 검색해 질문과 함께 prompt로 만든다. (Retrieve)\n",
    "\n",
    "![rag_vector_store](figures/rag_vector_store.png)\n",
    "\n",
    "## 벡터 데이터베이스란\n",
    "- 벡터 임베딩을 저장하고 관리하는 데이터베이스를 의미한다.\n",
    "- 모든 데이터는 적절한 임베딩 모델을 활용하면 임베딩 벡터로 변환할 수 있다. 이렇게 변환된 임베딩 벡터를 벡터 데이터베이스에 저장하면 **임베딩 벡터 간의 거리 계산을 통해 데이터 간 유사도를 검색할 수 있다.**\n",
    "    - **이미지, 텍스트, 음성 등 비정형 데이터**를 임베딩 모델로 **벡터화한 뒤 데이터베이스에 저장**한다.\n",
    "    - 벡터 간의 **유사도 계산**을 통해 연관성 있는 데이터나 유사한 데이터를 효과적으로 검색할 수 있다.\n",
    "    - 좋은 검색 결과를 위해서는 벡터의 품질이 중요하다. 그래서 **임베딩 모델(Embedding Model)을 잘 선택하는 것이 중요**하다.\n",
    "- 벡터 데이터베이스는 이러한 벡터 간 거리 계산에 특화된 데이터베이스다.\n",
    "\n",
    "## 주요 특징\n",
    "\n",
    "- **고차원 벡터 저장**\n",
    "  -  벡터 데이터베이스는 수백에서 수천 차원에 이르는 벡터 데이터를 효율적으로 저장하고 관리한다. \n",
    "  -  전통적인 데이터베이스로는 어려운 고차원 벡터 간 유사도 검색을 효율적으로 수행한다.\n",
    "- **유사성 기반 검색**\n",
    "  -  벡터 간의 거리를 측정하여 유사한 데이터를 빠르게 검색할 수 있다. \n",
    "  -  일반적으로 사용되는 거리계산기법은 다음과 같다.\n",
    "     - 코사인 유사도(Cosine Similarity)\n",
    "     - 유클리드 거리(Euclidean Distance)\n",
    "     - 맨하탄 거리(Manhattan Distance) \n",
    "- 비정형 데이터 처리: 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 변환하여 저장하고, 이러한 데이터를 효과적으로 검색할 수 있다.\n",
    "\n",
    "## 벡터 데이터베이스와 딥러닝\n",
    "- 벡터 데이터베이스는 딥러닝 기술의 발전과 깊은 관련이 있다.\n",
    "- 딥러닝 모델은 학습 과정에서 데이터의 특징을 추출하는 방법을 함께 학습한다. 충분한 데이터를 학습한 딥러닝 모델은 **데이터의 특성을 설명하는 특성 벡터(feature vector)를 효과적으로 생성**할 수 있다.\n",
    "- 이때 추출된 특성 벡터는 고차원 데이터(RAW Data)를 저차원 공간에서 표현한 **임베딩 벡터**다.\n",
    "    - > **임베딩**은 고차원 데이터를 저차원 공간으로 변환하여 표현하는 방법으로, 정보 손실을 최소화하면서 데이터 간의 의미 있는 관계를 벡터 공간에서 유지한다.\n",
    "- 딥러닝 모델로 추출한 데이터의 특징(feature vector)을 임베딩 공간에 배치하면, 비슷한 데이터는 가까이, 그렇지 않은 데이터는 멀리 배치된다.\n",
    "- 이러한 특성을 활용하면 임베딩 벡터 간의 거리를 계산해 유사한 데이터를 효과적으로 검색할 수 있다. 벡터 데이터베이스는 이러한 임베딩 벡터의 특성을 기반으로 개발되었다.\n",
    "- 딥러닝 기술의 발전과 폭넓은 활용으로 임베딩 데이터의 사용이 증가하면서, 이를 저장하고 관리하는 기능에 특화된 데이터베이스에 대한 수요도 증가해 다양한 벡터 데이터베이스가 등장했다.\n",
    "\n",
    "## 벡터 데이터베이스의 주요 기능\n",
    "1. **저장**  \n",
    "   - 이미지, 텍스트, 음성 등 **비정형 데이터**를 임베딩 모델을 통해 벡터로 변환한 뒤 벡터 데이터베이스에 저장한다.\n",
    "2. **검색**  \n",
    "   - 검색하려는 데이터를 임베딩 모델로 변환한 뒤, 벡터 데이터베이스에서 **유사도를 기반**으로 검색한다.\n",
    "3. **결과 반환**  \n",
    "   - 벡터 데이터베이스는 저장된 벡터 중 검색 쿼리 임베딩과 가장 가까운 벡터를 찾아 반환한다.\n",
    "\n",
    "## LLM과 벡터 데이터베이스\n",
    "- ChatGPT(LLM)의 등장 이후 벡터 데이터베이스는 폭발적인 주목을 받았다.\n",
    "- 임베딩 벡터의 유사도를 기반으로 문서를 검색하는 RAG(Relevant Augmented Generation) 기술은 LLM의 환각(할루시네이션) 현상을 줄이고, LLM을 추가 학습하지 않고도 최신 정보를 효율적으로 활용할 수 있는 핵심 기법으로 자리 잡았다.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65063-9482-4fdb-9ada-941eb08fb3b2",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 종류\n",
    "![img](figures/vector_database.png)\n",
    "\n",
    "<<https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c>>\n",
    "\n",
    "### 주요 벡터 데이터베이스 종류\n",
    "- **Pinecone**\n",
    "    - 클라우드 기반의 완전 관리형 벡터 데이터베이스 서비스로, 간단한 API를 통해 벡터 데이터를 관리할 수 있다.  \n",
    "    - 자동 확장성과 고가용성을 제공하며, 실시간 데이터 수집과 유사성 검색에 최적화되어 있다.\n",
    "    - 가장 쉽게 시작할 수 있는 관리형 서비스를 제공한다.\n",
    "- **Chroma**\n",
    "    - 벡터 임베딩을 효율적으로 저장하고 검색할 수 있는 오픈소스 데이터베이스로, AI 및 머신러닝 애플리케이션에 최적화되어 있다.\n",
    "    - 대규모 임베딩 저장에 최적화되어 있다.\n",
    "- **FAISS**\n",
    "    - Facebook AI에서 개발한 고성능 벡터 검색 라이브러리로, 고차원 벡터의 효율적인 유사성 검색을 위해 최적화되어 있다.\n",
    "    - GPU를 활용해 계산 성능을 높이며, 벡터 양자화 기술을 활용하여 메모리 사용을 최적화한다.\n",
    "    - 근사 최근접 이웃 검색(ANNS)에 최적화되어 있다.\n",
    "- **Milvus**\n",
    "    - 오픈소스 벡터 데이터베이스로, 대규모 벡터 데이터를 효율적으로 저장하고 검색할 수 있다.  \n",
    "    - 분산 아키텍처를 채택하여 확장성이 뛰어나며, IVF_PQ, DiskANN 등 다양한 인덱싱 알고리즘을 지원한다.\n",
    "    - 대규모 데이터셋 처리에 가장 적합한 솔루션이다.\n",
    "- **Weaviate**\n",
    "    - 오픈소스 벡터 데이터베이스로, 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 저장하고 검색할 수 있다.  \n",
    "    - GraphQL API를 통해 접근 가능하며, 내장된 머신러닝 모듈을 통해 가장 강력한 의미론적 검색 기능을 제공한다.\n",
    "- **Qdrant**\n",
    "    - Rust로 개발된 고성능 벡터 검색 엔진으로, 실시간 근사 최근접 이웃 검색을 제공한다.  \n",
    "    - 추천 시스템에 특화되어 있으며, 벡터 임베딩 저장과 유사도 쿼리를 효율적으로 수행한다.\n",
    "- **Elasticsearch**\n",
    "    - HNSW 알고리즘을 사용하여 벡터 검색을 구현하는 검색 엔진이다.\n",
    "    - 전통적인 검색 기능과 벡터 검색을 효과적으로 결합할 수 있어, 하이브리드 검색에 가장 적합하다.\n",
    "- **PGVector**\n",
    "    - PostgreSQL의 확장 모듈로, 벡터 데이터를 저장하고 유사성 검색을 수행할 수 있게 해준다.  \n",
    "    - SQL과 통합된 벡터 연산이 가능하며, L2 거리, 코사인 거리, 내적 등 다양한 거리 측정 방식을 지원한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3f6fe-c5e2-4c4f-9ef8-2cf5850f1bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1336f523-0b76-419c-8e46-fa96bdbcbdd6",
   "metadata": {},
   "source": [
    "# Langchain - Vector Store 연동 \n",
    "- Langchain은 다양한 벡터 데이터베이스와 연동할 수 있다.\n",
    "- 벡터 데이터베이스 마다 API가 다르기 때문에, Langchain을 사용하면 동일한 interface로 사용할 수 있다.\n",
    "\n",
    "## **VectorStore**\n",
    "- Langchain이 지원하는 모든 벡터 데이터베이스는 **VectorStore** 인터페이스를 구현한다.\n",
    "- 그래서 Langchain에서는 벡터 데이터베이스를 **Vector Store** 라고 한다.\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "### Vector Store 연결\n",
    "- Vector DB와 연결하는 메소드\n",
    "- `VectorStore.from_document()`\n",
    "  - Document들을 insert 하면서 연결.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - documents: insert할 문서들을 list[Document]로 전달.\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "-`VectorStore()`\n",
    "  - vector db와 연결만 한다.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "## InMemoryVectorStore\n",
    "- langchain에서 제공하는 메모리 기반 벡터 데이터베이스이다.\n",
    "- Data들을 Dictionary를 사용해 메모리에 저장하며, 검색 할 때 코사인 유사도(cosine similarity)를 계산하여 조회한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7fcddfb-0fd3-4cb8-a4f0-b72d1988d6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1092d6e3-2c41-426d-ac58-5f4ba1201ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# VectorStore 생성 시 Embedding 모델을 넣어 생성한다.\n",
    "\n",
    "# DB 연결\n",
    "vector_store = InMemoryVectorStore(embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40875638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 정의\n",
    "from langchain_core.documents import Document\n",
    "d1 = Document(\n",
    "    page_content=\"Apple, Pear, Watermelon\", # 문서 내용\n",
    "    id=\"1\", # 문서 ID (식별자)\n",
    "    metadata={\"category\": \"fruit\"} # 문서 정보\n",
    ")\n",
    "d2 = Document(\n",
    "    page_content=\"Python, C++, Java, C#, Rust\", # 문서 내용\n",
    "    id=\"2\", # 문서 ID (식별자)\n",
    "    metadata={\"category\": \"IT\"} # 문서 정보\n",
    ")\n",
    "d3 = Document(\n",
    "    page_content=\"Football, Baseball, Basketball\", # 문서 내용\n",
    "    id=\"3\", # 문서 ID (식별자)\n",
    "    metadata={\"category\": \"sports\"} # 문서 정보\n",
    ")\n",
    "docs = [d1, d2, d3]\n",
    "\n",
    "# VectorDB에 저장\n",
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ef65297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB와 연결하면서 Document들을 insert(upsert)\n",
    "vector_store2 = InMemoryVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7547f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 (query와 유사한 문서를 Vector Store에서 찾는다.)\n",
    "# query = \"SQL\"\n",
    "query = \"야구\"\n",
    "\n",
    "result = vector_store.similarity_search_with_score(query=query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a511430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='3', metadata={'category': 'sports'}, page_content='Football, Baseball, Basketball'),\n",
       "  0.5147806103942447),\n",
       " (Document(id='2', metadata={'category': 'IT'}, page_content='Python, C++, Java, C#, Rust'),\n",
       "  0.15766624806715804)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf88d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc4641-857c-47c1-80ff-5f4c2651a4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0da7c8f-c1be-4ddf-a935-90b22eac1f11",
   "metadata": {},
   "source": [
    "# 실습\n",
    "- `data/olympic.txt` 데이터 사용\n",
    "\n",
    "1. text loading\n",
    "2. text split\n",
    "3. embedding + vector store(InMemoryVectorStore)에 저장\n",
    "4. query(질의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349be3ce-539e-4d18-bc2b-67e8100ebcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152a3ac6-6f56-41ea-9c60-6a982226eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8d01f0-2fd7-4795-85a1-4ce9ea26a00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "# 1. 문서 loading + 2. Split(Chunking)\n",
    "loader = TextLoader(\"data/olympic.txt\", encoding=\"utf-8\")\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=50\n",
    ")\n",
    "docs = loader.load_and_split(splitter)\n",
    "# raw_docs = loader.load() -> docs = splitter.split_documents(raw_docs)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c1b2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/olympic.txt'}, page_content='올림픽')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2272080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b92635c0-d2ae-4185-a184-4c310e226573',\n",
       " '70d0a6e4-0367-494b-b7d9-12df943b2513',\n",
       " 'd23476ee-92d9-414d-ae5e-afcb2a2f5475',\n",
       " '9b17cfd5-603e-4aca-9193-3422bf621ed0',\n",
       " '93e37224-be82-4333-9c22-7707c6466e93',\n",
       " 'd1750e1a-f154-4750-9f0f-ca36a7d35f66',\n",
       " '4d6311fb-c983-405e-a19c-9c18675e91f3',\n",
       " '2c19d36c-b82e-4ad5-8f8e-106d1b2f5b91',\n",
       " '88bdb2c4-fd20-4032-a53a-3d3cf55730ea',\n",
       " '848af5af-2f96-4244-b7bb-303f029cf335',\n",
       " '1bad6756-50bc-48d3-9796-f5feecf1ccc1',\n",
       " '0b785787-5c28-4d45-8e73-77d86b8d6f81',\n",
       " 'a713cebf-892b-4470-80af-0f1924764404',\n",
       " 'e0084db3-a927-4483-98f2-2bc50512527c',\n",
       " '0aa75bd5-b327-4194-9745-12e864b5c415',\n",
       " '38f49e23-414d-43fa-a659-4896dce87c98',\n",
       " '5b2e447f-a533-47f0-a462-4bd1a84e6c28',\n",
       " '7ec9b680-ebe6-46e9-a63e-45d841048b6a',\n",
       " '86b81b99-4e07-441c-9a16-6893a317deaa',\n",
       " '90d43bc0-29ea-4361-b1cf-28677a00a753',\n",
       " '75a95f0c-b4b2-4b84-9aca-044bb98c6681',\n",
       " '68cbbeda-43a8-426a-9b55-0886fc684969',\n",
       " '479b92fd-cce2-4eaf-beba-c525847b4bb4',\n",
       " '195a1cf8-5574-4070-b4e6-8ae372fed83c',\n",
       " '0de16793-acd7-4799-bf53-af54905f5e36',\n",
       " '82662bc8-fa01-4ab9-8a22-201823330cdd',\n",
       " 'b1977247-f044-4069-a584-9191b17d4f26',\n",
       " 'b771b0c4-4b3a-4aee-aeaa-41a77e4fc8dd',\n",
       " '6b481147-54d8-47c2-866a-fbdc18e13f79',\n",
       " 'cf7463dd-6507-475e-a500-66014dd6faf5',\n",
       " '24dcc0ca-248c-40ba-8dfa-ba3362a80a62',\n",
       " 'e3862b7f-6b91-44d6-b69f-e1ed30c05988',\n",
       " '74c19ac8-6e50-409e-a32f-74f96fbbbafb',\n",
       " '8d5064c4-c0d8-4878-86a0-a37f3013ac47',\n",
       " '89289349-b5b9-4b56-9dfd-3f972eae1f94',\n",
       " 'b8f8df48-2e52-4afa-8e30-7cb052d8bbdd',\n",
       " 'f9bbd25a-205c-4498-b121-2de0fc0747b1',\n",
       " '039a4d58-2581-4c28-8bba-3f51c95fb3de',\n",
       " '6a74921a-0a03-46a1-997f-60044e340cdc',\n",
       " '443c1f20-854a-438b-af3d-7f65979a7a89',\n",
       " '5006fd78-988a-4319-bc07-fa9678ad6b52',\n",
       " '8e7ce0c8-b9e1-4419-9454-049f22144de5',\n",
       " 'e3c0f78d-69b3-4bfb-b3ae-09e669fee2df',\n",
       " '5df81ce6-a926-473f-a14e-f9f29e90994e',\n",
       " '73ad9d0c-21eb-42ce-95f9-dec059b742d0',\n",
       " 'b9b19f8c-dce5-4b03-805b-69823178c201',\n",
       " '9d6cbe39-c422-45af-ad2f-14b710df6515',\n",
       " '1800fa89-5e9f-443d-b87f-d29c3a3e6476',\n",
       " '128cae25-b4e3-465e-9827-8701974e167f',\n",
       " '34e4fc46-2aa4-4f4f-bfa9-e05687807edd',\n",
       " '7a8ffa19-6f14-4000-8d26-89aff0261257',\n",
       " '1e37f1bb-ffef-4862-b2c7-ee53c04158a8',\n",
       " '00f8f7d9-08d6-43f7-bd99-220dc4a136a1',\n",
       " 'fa48e2de-b970-45db-817b-cbcc2b106660',\n",
       " 'd93d6447-6031-48c6-8179-debdd0d34ff1',\n",
       " '34d3adf8-be91-4c37-9d82-9ff15734edc6',\n",
       " '5d7e0c5e-2bcb-46f7-b887-ced4e4a183f5',\n",
       " '932c65ff-3359-4ced-9927-4b33de6da2dd',\n",
       " '675931c8-c7bb-4f62-a674-96a8985b045c',\n",
       " '22ff4c1b-6ce9-4b5c-819c-037d6eb29c67',\n",
       " '2c0f88d4-aa7a-4df0-b21c-dab6dc7170ff']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. embedding + 4. VectorStore에 저장\n",
    "# VectorDB와 연결\n",
    "vector_store = InMemoryVectorStore(\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")  #임베딩모델\n",
    ")\n",
    "# 저장(embedding 처리후 저장 -> vector store가 임베딩 작업은 처리한다.)\n",
    "vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00aed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 + 저장\n",
    "# v2 = InMemoryVectorStore.from_documents(\n",
    "#     embedding=OpenAIEmbeddings(\"text-embedding-3-small\"),\n",
    "#     documents=docs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a464b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5847532901520429 하계올림픽\n",
      "0.5167171204610446 동계올림픽\n",
      "동계 올림픽은 눈과 얼음을 이용하는 스포츠들을 모아 이루어졌으며 하계 올림픽 때 실행하기 불가능한 종목들로 구성되어 있다. 피겨스케이팅, 아이스하키는 각각 1908년과 1920년에 하계올림픽 종목으로 들어가 있었다. IOC는 다른 동계 스포츠로 구성된 새로운 대회를 만들고 싶어 했고, 로잔에서 열린 1921년 올림픽 의회에서 겨울판 올림픽을 열기\n",
      "0.48757257538324067 올림픽\n",
      "0.47471668364853675 오늘날의 올림픽\n",
      "1896년 대회때는 14개국에서 241명의 선수단이 참가했지만 2008년 하계 올림픽때는 204개국에서 10,500명의 선수가 참가하는 등 세계적인 대회로 변모했다. 동계 올림픽의 규모는 하계 올림픽 규모보다 작다. 예를 들면 2006 토리노 동계 대회때는 80개국에서 2,508명의 선수가 참가했으며 82개 세부종목이 있었고, 2008 베이\n",
      "0.44939052012829395 고대올림픽\n"
     ]
    }
   ],
   "source": [
    "# 질문 -> 의미적 유사도가 높은 k(5)개의 문서를 반환.\n",
    "query = \"동계 올림픽에 대해 설명해주세요.\"    #input(\"질문:\")\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query=query, \n",
    "    k=5\n",
    ")\n",
    "for result in results:\n",
    "    print(result[1], result[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c15ed2-e9d6-4361-9d9e-0dfaf650de41",
   "metadata": {},
   "source": [
    "## MMR(최대 한계 관련성-Maximal Marginal Relevance) 알고리즘 적용\n",
    "최대 한계 관련성(Maximal Marginal Relevance, MMR) 알고리즘은 정보 검색 및 요약에서 검색 결과의 **관련성**과 **다양성**을 동시에 고려하여 최적의 결과를 제공하는 방법이다. \n",
    "이 알고리즘은 사용자 쿼리와의 관련성을 최대화하면서도 중복 정보를 최소화하여 다양한 정보를 제공하는 것을 목표로 한다.\n",
    "\n",
    "1. **관련성과 다양성의 균형 조절**: MMR은 사용자 쿼리와 문서 간의 유사성 점수와 이미 선택된 문서들과의 다양성 점수를 조합하여 각 문서의 최종 점수를 계산한다. 이를 통해 관련성이 높으면서도 중복되지 않는 문서를 선택한다.\n",
    "\n",
    "2. **수학적 정의**\n",
    "   $$\n",
    "   \\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')\n",
    "   $$\n",
    "\n",
    "   - $\\text{Sim}(d, Q)$: 문서 $d$와 쿼리 $\\text{Q}$ 사이의 유사성. (문서 유사성 계산)\n",
    "   - $\\max_{d' \\in D'} \\text{Sim}(d, d')$: 문서 $d$와 이미 선택된 문서 집합 $D'$ 중 가장 유사한 문서와의 유사성. (문서 다양성 계산)\n",
    "   - $\\lambda$: 유사성과 다양성의 중요도를 조절하는 매개변수(parameter)\n",
    "3. **적용 분야**: MMR은 정보 검색, 추천 시스템, 문서 요약 등에서 활용된다. 특히 LLM 검색에서 성능 향상이 입증되었다.\n",
    "\n",
    "### `vectorStore.max_marginal_relevance_search()` 메소드\n",
    "  - MMR 알고리즘을 적용한 검색을 수행한다.\n",
    "  - **파라미터**\n",
    "    - **query**: 사용자로부터 입력받은 검색 쿼리\n",
    "    - **k**: 최종적으로 선택할 문서의 수\n",
    "    - **fetch\\_k**: MMR 알고리즘 적용 시 고려할 상위 문서의 수\n",
    "    - **lambda_mult**: 쿼리와의 유사성과 선택된 문서 간의 다양성 사이의 균형을 조절하는 매개변수. $\\lambda = 1$이면 유사성만 고려하고, $\\lambda = 0$이면 다양성만을 최대화한다.\n",
    "    - **filter**: 검색 결과를 필터링할 조건을 지정한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92a398d-f0f6-416f-aad8-4c97ced68992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하계올림픽\n",
      "------------------\n",
      "- 국가 올림픽 위원회(NOC)는 각국의 올림픽 활동을 감독하는 기구이다. 예를 들어서 대한 올림픽 위원회(KOC)는 대한민국의 국가 올림픽 위원회이다. 현재 IOC에 소속된 국가 올림픽 위원회는 205개이다.\n",
      "- 올림픽 조직 위원회(OCOG)는 임시적인 조직으로 올림픽의 총체적인 것(개막식, 페막식 등)을 책임지기 위해 구성된 조직이다. 올림픽 조직 위원\n",
      "------------------\n",
      "고대 올림피아 경기가 처음 열린 시점은 보통 기원전 776년으로 인정되고 있는데, 이 연대는 그리스 올림피아에서 발견된 비문에 근거를 둔 것이다. 이 비문의 내용은 달리기 경주 승자 목록이며 기원전 776년부터 4년 이후 올림피아 경기 마다의 기록이 남겨져 있다. 고대 올림픽의 종목으로는 육상, 5종 경기(원반던지기, 창던지기, 달리기, 레슬링, 멀리뛰기)\n",
      "------------------\n",
      "동계올림픽\n",
      "동계 올림픽은 눈과 얼음을 이용하는 스포츠들을 모아 이루어졌으며 하계 올림픽 때 실행하기 불가능한 종목들로 구성되어 있다. 피겨스케이팅, 아이스하키는 각각 1908년과 1920년에 하계올림픽 종목으로 들어가 있었다. IOC는 다른 동계 스포츠로 구성된 새로운 대회를 만들고 싶어 했고, 로잔에서 열린 1921년 올림픽 의회에서 겨울판 올림픽을 열기\n",
      "------------------\n",
      "캐나다에서 열리는 두 번째 동계 올림픽이고, 동/하계 올림픽을 합쳐 캐나다에서 3번째로 개최되는 올림픽이다.\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"동계 올림픽에 대해 설명해줘.\"\n",
    "mmr_result = vector_store.max_marginal_relevance_search(\n",
    "    query=query,\n",
    "    k=5, #  최종 결과 문서 개수\n",
    "    fetch_k=20, # 처음 검색할 문서개수.\n",
    "    lambda_mult=0.5   # 1에 가까울수록 유사성에 0에 가까울 수록 다양성을 최대화.\n",
    ")\n",
    "\n",
    "for result in mmr_result:\n",
    "    print(result.page_content[:200])\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b3c9c-8f56-48fd-a952-9f79f0b75f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab46f5a-14b4-4b0d-a6ea-4dd855a452c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
